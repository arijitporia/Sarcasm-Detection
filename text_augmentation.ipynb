{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E95o3q1F_p5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/essays.csv',encoding =\"ISO-8859-1\",index_col=0)\n",
        "words=pd.read_excel('/content/drive/My Drive/emotion_words_for personality.xlsx',index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i47rAZueK_HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words=list(words[0])\n",
        "def filter(text, words=words):\n",
        "    S=[]\n",
        "    sents=text.split('.')\n",
        "    if len(sents) > 2:\n",
        "        for s in sents:\n",
        "            ss=s.split(' ')\n",
        "            ss=[g.lower() for g in ss]\n",
        "            if len(set(words).intersection(set(ss))) > 0:\n",
        "                S.append(s)\n",
        "    return (\".\".join(S))    \n",
        "df.TEXT = df.TEXT.apply(lambda x: filter(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyQipgUwjv1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.dropna(axis=0, how='any')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3076-WCLhhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from random import shuffle\n",
        "random.seed(1)\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#stop words list\n",
        "stop_words = stopwords.words(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_0Rf62kNakD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cleaning up text\n",
        "import re\n",
        "def get_only_chars(line):\n",
        "\n",
        "    clean_line = \"\"\n",
        "\n",
        "    line = line.replace(\"â€™\", \"\")\n",
        "    line = line.replace(\"'\", \"\")\n",
        "    line = line.replace(\"-\", \" \") #replace hyphens with spaces\n",
        "    line = line.replace(\"\\t\", \" \")\n",
        "    line = line.replace(\"\\n\", \" \")\n",
        "    line = line.lower()\n",
        "\n",
        "    for char in line:\n",
        "        if char in 'qwertyuiopasdfghjklzxcvbnm ':\n",
        "            clean_line += char\n",
        "        else:\n",
        "            clean_line += ' '\n",
        "\n",
        "    clean_line = re.sub(' +',' ',clean_line) #delete extra spaces\n",
        "    if clean_line[0] == ' ':\n",
        "        clean_line = clean_line[1:]\n",
        "    return clean_line\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ-B6noBP9gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10d1a25d-7e0b-407f-a1e6-8db9fe1902af"
      },
      "source": [
        "########################################################################\n",
        "# Synonym replacement\n",
        "# Replace n words in the sentence with synonyms from wordnet\n",
        "########################################################################\n",
        "\n",
        "#for the first time you use wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet \n",
        "\n",
        "def synonym_replacement(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\trandom_word_list = list(set([word for word in words if word not in stop_words]))\n",
        "\trandom.shuffle(random_word_list)\n",
        "\tnum_replaced = 0\n",
        "\tfor random_word in random_word_list:\n",
        "\t\tsynonyms = get_synonyms(random_word)\n",
        "\t\tif len(synonyms) >= 1:\n",
        "\t\t\tsynonym = random.choice(list(synonyms))\n",
        "\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n",
        "\t\t\t#print(\"replaced\", random_word, \"with\", synonym)\n",
        "\t\t\tnum_replaced += 1\n",
        "\t\tif num_replaced >= n: #only replace up to n words\n",
        "\t\t\tbreak\n",
        "\n",
        "\t#this is stupid but we need it, trust me\n",
        "\tsentence = ' '.join(new_words)\n",
        "\tnew_words = sentence.split(' ')\n",
        "\n",
        "\treturn new_words\n",
        "\n",
        "def get_synonyms(word):\n",
        "\tsynonyms = set()\n",
        "\tfor syn in wordnet.synsets(word): \n",
        "\t\tfor l in syn.lemmas(): \n",
        "\t\t\tsynonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "\t\t\tsynonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
        "\t\t\tsynonyms.add(synonym) \n",
        "\tif word in synonyms:\n",
        "\t\tsynonyms.remove(word)\n",
        "\treturn list(synonyms)\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cy8h3DpTa1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "# Random deletion\n",
        "# Randomly delete words from the sentence with probability p\n",
        "########################################################################\n",
        "\n",
        "def random_deletion(words, p):\n",
        "\n",
        "\t#obviously, if there's only one word, don't delete it\n",
        "\tif len(words) == 1:\n",
        "\t\treturn words\n",
        "\n",
        "\t#randomly delete words with probability p\n",
        "\tnew_words = []\n",
        "\tfor word in words:\n",
        "\t\tr = random.uniform(0, 1)\n",
        "\t\tif r > p:\n",
        "\t\t\tnew_words.append(word)\n",
        "\n",
        "\t#if you end up deleting all words, just return a random word\n",
        "\tif len(new_words) == 0:\n",
        "\t\trand_int = random.randint(0, len(words)-1)\n",
        "\t\treturn [words[rand_int]]\n",
        "\n",
        "\treturn new_words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLoWmpg8Tkx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "# Random swap\n",
        "# Randomly swap two words in the sentence n times\n",
        "########################################################################\n",
        "\n",
        "def random_swap(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\tfor _ in range(n):\n",
        "\t\tnew_words = swap_word(new_words)\n",
        "\treturn new_words\n",
        "\n",
        "def swap_word(new_words):\n",
        "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
        "\trandom_idx_2 = random_idx_1\n",
        "\tcounter = 0\n",
        "\twhile random_idx_2 == random_idx_1:\n",
        "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
        "\t\tcounter += 1\n",
        "\t\tif counter > 3:\n",
        "\t\t\treturn new_words\n",
        "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1] \n",
        "\treturn new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nmxtNciTpDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "# Random swap\n",
        "# Randomly swap two words in the sentence n times\n",
        "########################################################################\n",
        "\n",
        "def random_swap(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\tfor _ in range(n):\n",
        "\t\tnew_words = swap_word(new_words)\n",
        "\treturn new_words\n",
        "\n",
        "def swap_word(new_words):\n",
        "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
        "\trandom_idx_2 = random_idx_1\n",
        "\tcounter = 0\n",
        "\twhile random_idx_2 == random_idx_1:\n",
        "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
        "\t\tcounter += 1\n",
        "\t\tif counter > 3:\n",
        "\t\t\treturn new_words\n",
        "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1] \n",
        "\treturn new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVQQoIulTxZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "# Random insertion\n",
        "# Randomly insert n words into the sentence\n",
        "########################################################################\n",
        "\n",
        "def random_insertion(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\tfor _ in range(n):\n",
        "\t\tadd_word(new_words)\n",
        "\treturn new_words\n",
        "\n",
        "def add_word(new_words):\n",
        "\tsynonyms = []\n",
        "\tcounter = 0\n",
        "\twhile len(synonyms) < 1:\n",
        "\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n",
        "\t\tsynonyms = get_synonyms(random_word)\n",
        "\t\tcounter += 1\n",
        "\t\tif counter >= 10:\n",
        "\t\t\treturn\n",
        "\trandom_synonym = synonyms[0]\n",
        "\trandom_idx = random.randint(0, len(new_words)-1)\n",
        "\tnew_words.insert(random_idx, random_synonym)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plaPEO0TT2uP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "# main data augmentation function\n",
        "########################################################################\n",
        "\n",
        "def eda(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=10):\n",
        "\tsentence = get_only_chars(sentence)\n",
        "\twords = sentence.split(' ')\n",
        "\twords = [word for word in words if word is not '']\n",
        "\tnum_words = len(words)\n",
        "\taugmented_sentences = []\n",
        "\tnum_new_per_technique = int(num_aug/4)+1\n",
        "\tn_sr = max(1, int(alpha_sr*num_words))\n",
        "\tn_ri = max(1, int(alpha_ri*num_words))\n",
        "\tn_rs = max(1, int(alpha_rs*num_words))\n",
        "\n",
        "\t#sr\n",
        "\tfor _ in range(num_new_per_technique):\n",
        "\t\ta_words = synonym_replacement(words, n_sr)\n",
        "\t\taugmented_sentences.append(' '.join(a_words))\n",
        "\n",
        "\t#ri\n",
        "\tfor _ in range(num_new_per_technique):\n",
        "\t\ta_words = random_insertion(words, n_ri)\n",
        "\t\taugmented_sentences.append(' '.join(a_words))\n",
        "\n",
        "\t#rs\n",
        "\tfor _ in range(num_new_per_technique):\n",
        "\t\ta_words = random_swap(words, n_rs)\n",
        "\t\taugmented_sentences.append(' '.join(a_words))\n",
        "\n",
        "\t#rd\n",
        "\tfor _ in range(num_new_per_technique):\n",
        "\t\ta_words = random_deletion(words, p_rd)\n",
        "\t\taugmented_sentences.append(' '.join(a_words))\n",
        "\n",
        "\taugmented_sentences = [get_only_chars(sentence) for sentence in augmented_sentences]\n",
        "\tshuffle(augmented_sentences)\n",
        "\n",
        "\t#trim so that we have the desired number of augmented sentences\n",
        "\tif num_aug >= 1:\n",
        "\t\taugmented_sentences = augmented_sentences[:num_aug]\n",
        "\telse:\n",
        "\t\tkeep_prob = num_aug / len(augmented_sentences)\n",
        "\t\taugmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
        "\n",
        "\t#append the original sentence\n",
        "\taugmented_sentences.append(sentence)\n",
        "\n",
        "\treturn augmented_sentences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHMcXwl_UCyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=df.values\n",
        "data=[d for d in data if len(d[0])!=0]\n",
        "EDL=[]\n",
        "for d in data:\n",
        "    ed=eda(d[0])\n",
        "    l1=[d[1] for i in range(10)]\n",
        "    l2=[d[2] for i in range(10)]\n",
        "    l3=[d[3] for i in range(10)]\n",
        "    l4=[d[4] for i in range(10)]\n",
        "    l5=[d[5] for i in range(10)]\n",
        "    edl=list(zip(ed,l1,l2,l3,l4,l5))\n",
        "    edl=[list(p) for p in edl]\n",
        "    EDL.extend(edl)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0mJDaqEm4da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DD=data+EDL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cD_ik07nBc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DD=[list(dd) for dd in DD]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaKbGb_6nXIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Df=pd.DataFrame(DD,columns=list(df.columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6IEo2GpnyJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Df.to_csv('/content/drive/My Drive/essays_augmented.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}